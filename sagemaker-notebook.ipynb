{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface Summarization of Patent documents using Fine Tuned T5-Base with Big_Patent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "_**Note:**Â The use of Jupyter is optional: We could also launch SageMaker Training jobs from anywhere we have an SDK installed, connectivity to the cloud and appropriate permissions, such as a Laptop, another IDE or a task scheduler like Airflow or AWS Step Functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker>=2.48.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (2.69.0)\n",
      "Collecting sagemaker>=2.48.0\n",
      "  Using cached sagemaker-2.73.0.tar.gz (481 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers==4.6.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (4.6.1)\n",
      "Requirement already satisfied: datasets[s3]==1.6.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (1.6.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.1) (3.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.1) (4.49.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.1) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.1) (2020.11.13)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.1) (0.0.8)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.1) (3.4.1)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.1) (0.0.47)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.1) (21.3)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.1) (0.8)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.1) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.1) (1.19.2)\n",
      "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (6.0.1)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (2.0.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (1.1.5)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (2021.4.0)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (0.3.4)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (0.70.12.2)\n",
      "Requirement already satisfied: boto3==1.16.43 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (1.16.43)\n",
      "Requirement already satisfied: botocore==1.19.52 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (1.19.52)\n",
      "Requirement already satisfied: s3fs in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets[s3]==1.6.2) (2021.4.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3==1.16.43->datasets[s3]==1.6.2) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3==1.16.43->datasets[s3]==1.6.2) (0.3.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore==1.19.52->datasets[s3]==1.6.2) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore==1.19.52->datasets[s3]==1.6.2) (1.26.7)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.48.0) (20.3.0)\n",
      "  Using cached sagemaker-2.72.3.tar.gz (475 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sagemaker-2.72.2.tar.gz (473 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sagemaker-2.72.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.48.0) (1.0.1)\n",
      "  Using cached sagemaker-2.72.0.tar.gz (477 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sagemaker-2.71.0.tar.gz (477 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sagemaker-2.70.0.tar.gz (466 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.48.0) (0.2.8)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.48.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.48.0) (3.19.1)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker>=2.48.0) (0.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.1) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.1) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging->transformers==4.6.1) (2.4.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker>=2.48.0) (1.15.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers==4.6.1) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers==4.6.1) (2.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers==4.6.1) (2021.5.30)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->datasets[s3]==1.6.2) (2021.1)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker>=2.48.0) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker>=2.48.0) (1.6.6.4)\n",
      "Requirement already satisfied: aiobotocore>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from s3fs->datasets[s3]==1.6.2) (1.2.2)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers==4.6.1) (1.0.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers==4.6.1) (7.1.2)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.12.1)\n",
      "Requirement already satisfied: aiohttp>=3.3.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (3.8.1)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (0.7.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.6.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (5.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.2.0)\n",
      "Requirement already satisfied: idna-ssl>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.1.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (4.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sagemaker>=2.48.0\" \"transformers==4.6.1\" \"datasets[s3]==1.6.2\" --upgrade\n",
    "#!apt install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected operating system as amzn/2018.\n",
      "Checking for curl...\n",
      "Detected curl...\n",
      "Downloading repository file: https://packagecloud.io/install/repositories/github/git-lfs/config_file.repo?os=amzn&dist=2018&source=script\n",
      "done.\n",
      "Installing pygpgme to verify GPG signatures...\n",
      "Loaded plugins: dkms-build-requires, priorities, update-motd, upgrade-helper,\n",
      "              : versionlock\n",
      "amzn-main                                                | 2.1 kB     00:00     \n",
      "amzn-updates                                             | 3.8 kB     00:00     \n",
      "copr:copr.fedorainfracloud.org:vbatts:shadow-utils-newxi | 3.3 kB     00:00     \n",
      "github_git-lfs-source/signature                          |  833 B     00:00     \n",
      "github_git-lfs-source/signature                          | 1.8 kB     00:00 !!! \n",
      "libnvidia-container/x86_64/signature                     |  833 B     00:00     \n",
      "libnvidia-container/x86_64/signature                     | 2.1 kB     00:00 !!! \n",
      "nvidia-container-runtime/x86_64/signature                |  833 B     00:00     \n",
      "nvidia-container-runtime/x86_64/signature                | 2.1 kB     00:00 !!! \n",
      "nvidia-docker/x86_64/signature                           |  833 B     00:00     \n",
      "nvidia-docker/x86_64/signature                           | 2.1 kB     00:00 !!! \n",
      "Package python26-pygpgme-0.3-9.12.amzn1.x86_64 already installed and latest version\n",
      "Nothing to do\n",
      "Installing yum-utils...\n",
      "Loaded plugins: dkms-build-requires, priorities, update-motd, upgrade-helper,\n",
      "              : versionlock\n",
      "Package yum-utils-1.1.31-46.30.amzn1.noarch already installed and latest version\n",
      "Nothing to do\n",
      "Generating yum cache for github_git-lfs...\n",
      "Generating yum cache for github_git-lfs-source...\n",
      "\n",
      "The repository is setup! You can now install packages.\n",
      "Loaded plugins: dkms-build-requires, priorities, update-motd, upgrade-helper,\n",
      "              : versionlock\n",
      "1 packages excluded due to repository priority protections\n",
      "Package git-lfs-2.12.1-1.el6.x86_64 already installed and latest version\n",
      "Nothing to do\n",
      "Updated git hooks.\n",
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.rpm.sh | sudo bash\n",
    "!sudo yum install git-lfs -y\n",
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker.huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_If you are going to use Sagemaker in a local environment. You need access to an IAM Role with the required permissions for Sagemaker. You can find [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) more about it._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAM role arn used for running training: arn:aws:iam::859830842924:role/service-role/AmazonSageMaker-ExecutionRole-20211013T235227\n",
      "S3 bucket used for storing artifacts: sagemaker-us-east-1-859830842924\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"IAM role arn used for running training: {role}\")\n",
    "print(f\"S3 bucket used for storing artifacts: {sess.default_bucket()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.6.1'} # v4.6.1 is referring to the `transformers_version` you use in the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure distributed training and hyperparameters\n",
    "\n",
    "Next, we will define our `hyperparameters` and configure our distributed training strategy. As hyperparameter, we can define any [Seq2SeqTrainingArguments](https://huggingface.co/transformers/main_classes/trainer.html#seq2seqtrainingarguments) and the ones defined in [run_summarization.py](https://github.com/huggingface/transformers/tree/master/examples/seq2seq#sequence-to-sequence-training-and-evaluation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine Tune T5-base model with big_patent dataset\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'per_device_train_batch_size': 2,\n",
    "                 'per_device_eval_batch_size': 2,\n",
    "                 'model_name_or_path': 't5-base', # https://huggingface.co/t5-base\n",
    "                 'dataset_name': 'xsum', \n",
    "                 # goal is to train using Big_Patent, currently doing xsum as it's smaller/faster.\n",
    "                 # https://huggingface.co/datasets/big_patent\n",
    "                 # 'dataset_name': 'big_patent',\n",
    "                 # 'dataset_config_name': 'g',\n",
    "                 'do_train': True,\n",
    "                 'do_eval': True,\n",
    "                 #'do_predict': True, # not using while testing\n",
    "                 #'predict_with_generate': True, # not using while testing\n",
    "                 # 'output_dir': '/opt/ml/checkpoints', # defaults to '/opt/ml/model', results in output tar.gz containing all checkpoint files.\n",
    "                 'num_train_epochs': 1,\n",
    "                 'learning_rate': 5e-5,\n",
    "                 'seed': 7,\n",
    "                 'fp16': True,\n",
    "                 #'cache_dir': '/tmp',\n",
    "                 # for big_patent...\n",
    "                 # 'text_column': 'description',\n",
    "                 # 'summary_column': 'abstract',\n",
    "                 # for xsum...\n",
    "                 'text_column': 'document',\n",
    "                 'summary_column': 'summary',\n",
    "                 #'enable_checkpointing' = False, # errors, must not be a HP of the HF trainer??? \n",
    "                 'save_total_limit': 1 # adding to test remove all prev checkpoints from output file - https://huggingface.co/docs/transformers/v4.15.0/en/main_classes/trainer#transformers.TrainingArguments\n",
    "                }\n",
    "\n",
    "# configuration for running training on smdistributed Data Parallel\n",
    "distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "\n",
    "# set S3 output location for checkpoints\n",
    "checkpoint_s3_uri=f's3://{sess.default_bucket()}/checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a `HuggingFace` estimator and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "      entry_point='run_summarization.py', # script\n",
    "      source_dir='./examples/pytorch/summarization', # relative path to example\n",
    "      git_config=git_config,\n",
    "      instance_type='ml.p3.16xlarge',\n",
    "      instance_count=2,\n",
    "      transformers_version='4.6.1',\n",
    "      pytorch_version='1.7.1',\n",
    "      py_version='py36',\n",
    "      role=role,\n",
    "      hyperparameters = hyperparameters,\n",
    "      distribution = distribution,\n",
    "      volume_size = 400, # allocating ridiculous amount of EBS so checkpoints don't kill job.\n",
    "      enable_checkpointing = False, # does not work for HF Estimator it seems\n",
    "      checkpoint_s3_uri = checkpoint_s3_uri # doesn't seem to help, checkpoints still stored\n",
    "      # cache_dir='/tmp' # doesn't seem to help, checkpoints still stored\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the train job\n",
    "huggingface_estimator.fit()\n",
    "# save model to\n",
    "huggingface_estimator.save_model('/opt/ml/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the endpoint from Estimator\n",
    "\n",
    "To deploy our endpoint, we call `deploy()` on our HuggingFace estimator object, passing in our desired number of instances and instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = huggingface_estimator.deploy(1,\"ml.g4dn.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the endpoint from Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=\"s3://sagemaker-us-east-1-859830842924/huggingface-pytorch-training-2022-01-24-12-30-55-527/output/model.tar.gz\",  # path to your trained SageMaker model\n",
    "   role=role,                                            # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.6\",                           # Transformers version used\n",
    "   pytorch_version=\"1.7\",                                # PyTorch version used\n",
    "   py_version='py36',                                    # Python version used\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the returned predictor object to call the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent = '''BACKGROUND OF THE DISCLOSURE\n",
    "\n",
    "      1. Technical Field of the Disclosure\n",
    "      This embodiment relates in general to electric cars. More specifically, the preferred embodiment relates to an electric car having a vertical row of seats.\n",
    "      2. Description of the Related Art\n",
    "      An electric car is powered by an electric motor using electrical energy stored in batteries or other charged devices. Electric cars are environment friendly as it do not produce any harmful gases such as carbon monoxide, organic compounds, hydro carbons etc. Electric cars are economical because of very low maintenance and operating costs.\n",
    "      Conventional electric cars have considerable drawbacks. For example, an existing electric car includes an electric drive and at least one connected electrical energy storage module. A guide extends longitudinally along the motor vehicle, and supports the storage module in a manner relative to the motor vehicle. Conventional electric cars employ horizontal rows of seats consuming excess space.\n",
    "      Another existing electric vehicle is capable of carrying at least two passengers and has at least three wheels. Passengers sit in tandem and most of the batteries or fuel cell systems are located to the sides of the passengers. This vehicle has an aerodynamically shaped body with substantially reduced frontal area and drag. The body is lightweight, made from shock absorbing materials and structures, and has pressure-airless tires, which enhances the safety of the passengers. The vehicle also includes an advanced hydrogen-electric hybrid propulsion system with quick refueling from existing infrastructure and various additional optional features and systems. However the batteries or fuel cell systems are placed to the sides of the passengers which increases the overall the dimension and weight of the vehicle.\n",
    "      Yet another existing electrical car embodiment is comprised of bodywork with ground-engaging wheels for vehicle motion over the ground, the bodywork contains an electric motor to drive the vehicle via the wheels and batteries to power the electric motor.\n",
    "      This embodiment provides an additional energy generation means comprised of a tunnel extending through the bodywork. It includes a turbine fan/alternator set located in the tunnel at the rear of the vehicle where electrical energy is generated during vehicle motion to charge the batteries. This results in improved performance of the vehicle, especially with regard to its range. The inlet to the tunnel at the vehicle front constitutes the major portion of the vehicles frontal area. A special alternator is provided, and the vehicle can also include a solar cell means for battery charging. However, the seats are placed far apart which consumes a lot of space.\n",
    "      Hence, it can be seen, that there is a need for an electric car that contains a vertical rows of seats. This needed electric car would save more space than existing models to form a vehicle of smaller size with more passengers. Moreover, this needed electric car would consume less power and use a less bulky charging means during transportation. The present embodiment accomplishes these objectives.\n",
    "SUMMARY OF THE DISCLOSURE\n",
    "\n",
    "      To minimize the limitations found in the prior art, and to minimize other limitations that will be apparent upon the reading of the specifications, the present invention provides an electric car having a vertical row of seat for accommodating at least one passenger. The electric car comprises a center console placed at an interior forepart of the electric car. A steering is attached to the center console. A rectangular seat is mounted on a rectangular box, the rectangular box being longitudinally placed at a center part of the electric car. A storage area is enclosed within the rectangular box, the storage area includes a personal storage and a battery storage. The battery storage includes a battery pack having a set of rechargeable batteries. The battery pack is used to power the electric car. A plug point is located at a rear end of the electric car for charging the battery pack. A pair of rotatable front wheels and a pair of rotatable back wheels are provided for ensuring smooth movement of the electric car. Both the center console and the steering of the electric car are aligned with the rectangular seat. The rectangular seat is mounted on the rectangular box having the storage area in order to save space. The electric car is configured to have a compact seating arrangement. A back support may be provided for a driver's rectangular seat. The electric car is specially designed to achieve better performance by increasing the energy efficiency and reducing the power consumption. The at least one passenger can be seated facing front direction with one leg on each side of the rectangular seat. The electric car is capable of accommodating more passengers with relatively small size and with minimum power consumption during transportation.\n",
    "      In alternate embodiment of the present invention at least one step and ladder seat is positioned at the center part of the electric car. The electric car comprises a car body having a front end, a rear end, a top portion and a bottom portion. A center console placed at an interior forepart of the electric car. A steering is attached to the center console. At least one step and ladder seat is positioned at the center part of the electric car for accommodating at least one passenger. In addition to the at least one step and ladder seat, a horizontal row of seats for accommodating a pair of passengers is located at the rear end of the vehicle. A battery storage having a battery pack is positioned at the bottom portion of step and ladder seat for powering the electric car. A plug point is located at a rear end of the electric car for charging the battery pack. A personal storage is placed at the rear end of horizontal row of seat.\n",
    "      One objective of the invention is to provide an electric car capable of accommodating four or more passengers with relatively smaller vehicle size.\n",
    "      Another objective of the invention is to provide an electric car with compact seating arrangement.\n",
    "      A third objective of the invention is to provide an electric car with better performance by increasing the energy efficiency and reducing the power consumption.\n",
    "      These and other advantages and features of the present invention are described with specificity so as to make the present invention understandable to one of ordinary skill in the art.'''\n",
    "\n",
    "data= {\"inputs\":patent}\n",
    "\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we delete the endpoint again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
